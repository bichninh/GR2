{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf36e9d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 4, 4, 256)         295168    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 4097      \n",
      "=================================================================\n",
      "Total params: 522,497\n",
      "Trainable params: 522,497\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n"
     ]
    }
   ],
   "source": [
    "# example of defining the discriminator model\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.utils import plot_model\n",
    "# define the standalone discriminator model\n",
    "def define_discriminator(in_shape=(32,32,3)):\n",
    " model = Sequential()\n",
    "# normal\n",
    " model.add(Conv2D(64, (3,3), padding='same', input_shape=in_shape))\n",
    " model.add(LeakyReLU(alpha=0.2))\n",
    "# downsample\n",
    " model.add(Conv2D(128, (3,3), strides=(2,2), padding='same'))\n",
    " model.add(LeakyReLU(alpha=0.2))\n",
    "# downsample\n",
    " model.add(Conv2D(128, (3,3), strides=(2,2), padding='same'))\n",
    " model.add(LeakyReLU(alpha=0.2))\n",
    "# downsample\n",
    " model.add(Conv2D(256, (3,3), strides=(2,2), padding='same'))\n",
    " model.add(LeakyReLU(alpha=0.2))\n",
    "# classifier\n",
    " model.add(Flatten())\n",
    " model.add(Dropout(0.4))\n",
    " model.add(Dense(1, activation='sigmoid'))\n",
    "# compile model\n",
    " opt = Adam(lr=0.0002, beta_1=0.5)\n",
    " model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    " return model\n",
    "# define model\n",
    "model = define_discriminator()\n",
    "# summarize the model\n",
    "model.summary()\n",
    "# plot the model\n",
    "plot_model(model, to_file='discriminator_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b74bc61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">1 real=42% fake=5%\n",
      ">2 real=95% fake=8%\n",
      ">3 real=98% fake=31%\n",
      ">4 real=98% fake=61%\n",
      ">5 real=97% fake=91%\n",
      ">6 real=95% fake=100%\n",
      ">7 real=92% fake=100%\n",
      ">8 real=98% fake=100%\n",
      ">9 real=97% fake=100%\n",
      ">10 real=97% fake=100%\n",
      ">11 real=95% fake=100%\n",
      ">12 real=100% fake=100%\n",
      ">13 real=98% fake=100%\n",
      ">14 real=97% fake=100%\n",
      ">15 real=100% fake=100%\n",
      ">16 real=98% fake=100%\n",
      ">17 real=98% fake=100%\n",
      ">18 real=100% fake=100%\n",
      ">19 real=100% fake=100%\n",
      ">20 real=100% fake=100%\n"
     ]
    }
   ],
   "source": [
    "# example of training the discriminator model on real and random cifar10 images\n",
    "import tensorflow as tf\n",
    "from numpy import ones\n",
    "from numpy import zeros\n",
    "from numpy.random import rand\n",
    "from numpy.random import randint\n",
    "from tensorflow.keras.datasets.cifar10 import load_data\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "# define the standalone discriminator model\n",
    "def define_discriminator(in_shape=(32,32,3)):\n",
    " model = Sequential()\n",
    "# normal\n",
    " model.add(Conv2D(64, (3,3), padding='same', input_shape=in_shape))\n",
    " model.add(LeakyReLU(alpha=0.2))\n",
    "# downsample\n",
    " model.add(Conv2D(128, (3,3), strides=(2,2), padding='same'))\n",
    " model.add(LeakyReLU(alpha=0.2))\n",
    "# downsample\n",
    " model.add(Conv2D(128, (3,3), strides=(2,2), padding='same'))\n",
    " model.add(LeakyReLU(alpha=0.2))\n",
    "# downsample\n",
    " model.add(Conv2D(256, (3,3), strides=(2,2), padding='same'))\n",
    " model.add(LeakyReLU(alpha=0.2))\n",
    "# classifier\n",
    " model.add(Flatten())\n",
    " model.add(Dropout(0.4))\n",
    " model.add(Dense(1, activation='sigmoid'))\n",
    "# compile model\n",
    " opt = Adam(lr=0.0002, beta_1=0.5)\n",
    " model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    " return model\n",
    "# load and prepare cifar10 training images\n",
    "def load_real_samples():\n",
    "# load cifar10 dataset\n",
    " (trainX, _), (_, _) = load_data()\n",
    "# convert from unsigned ints to floats\n",
    " X = trainX.astype('float32')\n",
    "# scale from [0,255] to [-1,1]\n",
    " X = (X - 127.5) / 127.5\n",
    " return X\n",
    "# select real samples\n",
    "def generate_real_samples(dataset, n_samples):\n",
    "# choose random instances\n",
    " ix = randint(0, dataset.shape[0], n_samples)\n",
    "# retrieve selected images\n",
    " X = dataset[ix]\n",
    "# generate ✬real✬ class labels (1)\n",
    " y = ones((n_samples, 1))\n",
    " return X, y\n",
    "# generate n fake samples with class labels\n",
    "def generate_fake_samples(n_samples):\n",
    "# generate uniform random numbers in [0,1]\n",
    " X = rand(32 * 32 * 3 * n_samples)\n",
    "# update to have the range [-1, 1]\n",
    " X = -1 + X * 2\n",
    "# reshape into a batch of color images\n",
    " X = X.reshape((n_samples, 32, 32, 3))\n",
    "# generate ✬fake✬ class labels (0)\n",
    " y = zeros((n_samples, 1))\n",
    " return X, y\n",
    "# train the discriminator model\n",
    "def train_discriminator(model, dataset, n_iter=20, n_batch=128):\n",
    " half_batch = int(n_batch / 2)\n",
    "# manually enumerate epochs\n",
    " for i in range(n_iter):\n",
    "# get randomly selected ✬real✬ samples\n",
    "  X_real, y_real = generate_real_samples(dataset, half_batch)\n",
    "# update discriminator on real samples\n",
    "  _, real_acc = model.train_on_batch(X_real, y_real)\n",
    "# generate ✬fake✬ examples\n",
    "  X_fake, y_fake = generate_fake_samples(half_batch)\n",
    "# update discriminator on fake samples\n",
    "  _, fake_acc = model.train_on_batch(X_fake, y_fake)\n",
    "# summarize performance\n",
    "  print('>%d real=%.0f%% fake=%.0f%%' % (i+1, real_acc*100, fake_acc*100))\n",
    "# define the discriminator model\n",
    "model = define_discriminator()\n",
    "# load image data\n",
    "dataset = load_real_samples()\n",
    "# fit the model\n",
    "train_discriminator(model, dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1003d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
