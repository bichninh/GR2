{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c32fcf63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 14, 14, 64)        640       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 3137      \n",
      "=================================================================\n",
      "Total params: 40,705\n",
      "Trainable params: 40,705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n"
     ]
    }
   ],
   "source": [
    "# example of defining the discriminator model\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.utils import plot_model\n",
    "# define the standalone discriminator model\n",
    "def define_discriminator(in_shape=(28,28,1)):\n",
    " model = Sequential()\n",
    " model.add(Conv2D(64, (3,3), strides=(2, 2), padding=\"same\", input_shape=in_shape))\n",
    " model.add(LeakyReLU(alpha=0.2))\n",
    " model.add(Dropout(0.4))\n",
    " model.add(Conv2D(64, (3,3), strides=(2, 2), padding=\"same\"))\n",
    " model.add(LeakyReLU(alpha=0.2))\n",
    " model.add(Dropout(0.4))\n",
    " model.add(Flatten())\n",
    " model.add(Dense(1, activation=\"sigmoid\"))\n",
    "# compile model\n",
    " opt = Adam(lr=0.0002, beta_1=0.5)\n",
    " model.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    " return model\n",
    "# define model\n",
    "model = define_discriminator()\n",
    "# summarize the model\n",
    "model.summary()\n",
    "# plot the model\n",
    "plot_model(model, to_file=\"discriminator_plot.png\", show_shapes=True, show_layer_names=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6f63352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and prepare mnist training images\n",
    "def load_real_samples():\n",
    "# load mnist dataset\n",
    " (trainX, _), (_, _) = load_data()\n",
    "# expand to 3d, e.g. add channels dimension\n",
    " X = expand_dims(trainX, axis=-1)\n",
    "# convert from unsigned ints to floats\n",
    " X = X.astype(\"float32\")\n",
    "# scale from [0,255] to [0,1]\n",
    " X = X / 255.0\n",
    " return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a6357a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select real samples\n",
    "def generate_real_samples(dataset, n_samples):\n",
    "# choose random instances\n",
    " ix = randint(0, dataset.shape[0], n_samples)\n",
    "# retrieve selected images\n",
    " X = dataset[ix]\n",
    "# generate ✬real✬ class labels (1)\n",
    " y = ones((n_samples, 1))\n",
    " return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4011d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate n fake samples with class labels\n",
    "def generate_fake_samples(n_samples):\n",
    "# generate uniform random numbers in [0,1]\n",
    " X = rand(28 * 28 * n_samples)\n",
    "# reshape into a batch of grayscale images\n",
    " X = X.reshape((n_samples, 28, 28, 1))\n",
    "# generate ✬fake✬ class labels (0)\n",
    " y = zeros((n_samples, 1))\n",
    " return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f65f7e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">1 real=46% fake=52%\n",
      ">2 real=52% fake=75%\n",
      ">3 real=59% fake=82%\n",
      ">4 real=55% fake=96%\n",
      ">5 real=58% fake=98%\n",
      ">6 real=61% fake=99%\n",
      ">7 real=55% fake=100%\n",
      ">8 real=59% fake=100%\n",
      ">9 real=59% fake=100%\n",
      ">10 real=65% fake=100%\n",
      ">11 real=71% fake=100%\n",
      ">12 real=66% fake=100%\n",
      ">13 real=71% fake=100%\n",
      ">14 real=72% fake=100%\n",
      ">15 real=72% fake=100%\n",
      ">16 real=74% fake=100%\n",
      ">17 real=75% fake=100%\n",
      ">18 real=77% fake=100%\n",
      ">19 real=84% fake=100%\n",
      ">20 real=86% fake=100%\n",
      ">21 real=83% fake=100%\n",
      ">22 real=95% fake=100%\n",
      ">23 real=93% fake=100%\n",
      ">24 real=93% fake=100%\n",
      ">25 real=90% fake=100%\n",
      ">26 real=94% fake=100%\n",
      ">27 real=95% fake=100%\n",
      ">28 real=98% fake=100%\n",
      ">29 real=98% fake=100%\n",
      ">30 real=98% fake=100%\n",
      ">31 real=98% fake=100%\n",
      ">32 real=98% fake=100%\n",
      ">33 real=98% fake=100%\n",
      ">34 real=99% fake=100%\n",
      ">35 real=100% fake=100%\n",
      ">36 real=100% fake=100%\n",
      ">37 real=99% fake=100%\n",
      ">38 real=100% fake=100%\n",
      ">39 real=99% fake=100%\n",
      ">40 real=99% fake=100%\n",
      ">41 real=100% fake=100%\n",
      ">42 real=100% fake=100%\n",
      ">43 real=100% fake=100%\n",
      ">44 real=99% fake=100%\n",
      ">45 real=100% fake=100%\n",
      ">46 real=100% fake=100%\n",
      ">47 real=100% fake=100%\n",
      ">48 real=100% fake=100%\n",
      ">49 real=100% fake=100%\n",
      ">50 real=100% fake=100%\n",
      ">51 real=100% fake=100%\n",
      ">52 real=100% fake=100%\n",
      ">53 real=100% fake=100%\n",
      ">54 real=100% fake=100%\n",
      ">55 real=100% fake=100%\n",
      ">56 real=100% fake=100%\n",
      ">57 real=100% fake=100%\n",
      ">58 real=100% fake=100%\n",
      ">59 real=100% fake=100%\n",
      ">60 real=100% fake=100%\n",
      ">61 real=100% fake=100%\n",
      ">62 real=100% fake=100%\n",
      ">63 real=100% fake=100%\n",
      ">64 real=100% fake=100%\n",
      ">65 real=100% fake=100%\n",
      ">66 real=100% fake=100%\n",
      ">67 real=100% fake=100%\n",
      ">68 real=100% fake=100%\n",
      ">69 real=100% fake=100%\n",
      ">70 real=100% fake=100%\n",
      ">71 real=100% fake=100%\n",
      ">72 real=100% fake=100%\n",
      ">73 real=100% fake=100%\n",
      ">74 real=100% fake=100%\n",
      ">75 real=100% fake=100%\n",
      ">76 real=100% fake=100%\n",
      ">77 real=100% fake=100%\n",
      ">78 real=100% fake=100%\n",
      ">79 real=100% fake=100%\n",
      ">80 real=100% fake=100%\n",
      ">81 real=100% fake=100%\n",
      ">82 real=100% fake=100%\n",
      ">83 real=100% fake=100%\n",
      ">84 real=100% fake=100%\n",
      ">85 real=100% fake=100%\n",
      ">86 real=100% fake=100%\n",
      ">87 real=100% fake=100%\n",
      ">88 real=100% fake=100%\n",
      ">89 real=100% fake=100%\n",
      ">90 real=100% fake=100%\n",
      ">91 real=100% fake=100%\n",
      ">92 real=100% fake=100%\n",
      ">93 real=100% fake=100%\n",
      ">94 real=100% fake=100%\n",
      ">95 real=100% fake=100%\n",
      ">96 real=100% fake=100%\n",
      ">97 real=100% fake=100%\n",
      ">98 real=100% fake=100%\n",
      ">99 real=100% fake=100%\n",
      ">100 real=100% fake=100%\n"
     ]
    }
   ],
   "source": [
    "# example of training the discriminator model on real and random mnist images\n",
    "import tensorflow as tf\n",
    "from numpy import expand_dims\n",
    "from numpy import ones\n",
    "from numpy import zeros\n",
    "from numpy.random import rand\n",
    "from numpy.random import randint\n",
    "from tensorflow.keras.datasets.mnist import load_data\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "# define the standalone discriminator model\n",
    "def define_discriminator(in_shape=(28,28,1)):\n",
    " model = Sequential()\n",
    " model.add(Conv2D(64, (3,3), strides=(2, 2), padding=\"same\", input_shape=in_shape))\n",
    " model.add(LeakyReLU(alpha=0.2))\n",
    " model.add(Dropout(0.4))\n",
    " model.add(Conv2D(64, (3,3), strides=(2, 2), padding=\"same\"))\n",
    " model.add(LeakyReLU(alpha=0.2))\n",
    " model.add(Dropout(0.4))\n",
    " model.add(Flatten())\n",
    " model.add(Dense(1, activation=\"sigmoid\"))\n",
    "# compile model\n",
    " opt = Adam(lr=0.0002, beta_1=0.5)\n",
    " model.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    " return model\n",
    "# load and prepare mnist training images\n",
    "def load_real_samples():\n",
    "# load mnist dataset\n",
    " (trainX, _), (_, _) = load_data()\n",
    "# expand to 3d, e.g. add channels dimension\n",
    " X = expand_dims(trainX, axis=-1)\n",
    "# convert from unsigned ints to floats\n",
    " X = X.astype(\"float32\")\n",
    "# scale from [0,255] to [0,1]\n",
    " X = X / 255.0\n",
    " return X\n",
    "# select real samples\n",
    "def generate_real_samples(dataset, n_samples):\n",
    "# choose random instances\n",
    " ix = randint(0, dataset.shape[0], n_samples)\n",
    "# retrieve selected images\n",
    " X = dataset[ix]\n",
    "# generate ✬real✬ class labels (1)\n",
    " y = ones((n_samples, 1))\n",
    " return X, y\n",
    "# generate n fake samples with class labels\n",
    "def generate_fake_samples(n_samples):\n",
    "# generate uniform random numbers in [0,1]\n",
    " X = rand(28 * 28 * n_samples)\n",
    "# reshape into a batch of grayscale images\n",
    " X = X.reshape((n_samples, 28, 28, 1))\n",
    "# generate ✬fake✬ class labels (0)\n",
    " y = zeros((n_samples, 1))\n",
    " return X, y\n",
    "# train the discriminator model\n",
    "def train_discriminator(model, dataset, n_iter=100, n_batch=256):\n",
    " half_batch = int(n_batch / 2)\n",
    "# manually enumerate epochs\n",
    " for i in range(n_iter):\n",
    "# get randomly selected ✬real✬ samples\n",
    "  X_real, y_real = generate_real_samples(dataset, half_batch)\n",
    "# update discriminator on real samples\n",
    "  _, real_acc = model.train_on_batch(X_real, y_real)\n",
    "# generate ✬fake✬ examples\n",
    "  X_fake, y_fake = generate_fake_samples(half_batch)\n",
    "# update discriminator on fake samples\n",
    "  _, fake_acc = model.train_on_batch(X_fake, y_fake)\n",
    "# summarize performance\n",
    "  print('>%d real=%.0f%% fake=%.0f%%' % (i+1, real_acc*100, fake_acc*100))\n",
    "# define the discriminator model\n",
    "model = define_discriminator()\n",
    "# load image data\n",
    "dataset = load_real_samples()\n",
    "# fit the model\n",
    "train_discriminator(model, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c96a7a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
