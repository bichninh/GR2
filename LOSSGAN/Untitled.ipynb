{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d4acb3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5851, 28, 28, 1)\n",
      ">1, d1=0.681, d2=0.694 g=0.692, a1=95, a2=0\n",
      ">2, d1=0.641, d2=0.695 g=0.692, a1=100, a2=0\n",
      ">3, d1=0.605, d2=0.696 g=0.690, a1=100, a2=0\n",
      ">4, d1=0.571, d2=0.700 g=0.687, a1=100, a2=0\n",
      ">5, d1=0.534, d2=0.707 g=0.680, a1=100, a2=0\n",
      ">6, d1=0.493, d2=0.718 g=0.669, a1=100, a2=0\n",
      ">7, d1=0.451, d2=0.738 g=0.652, a1=100, a2=0\n",
      ">8, d1=0.411, d2=0.767 g=0.628, a1=100, a2=0\n",
      ">9, d1=0.375, d2=0.809 g=0.600, a1=100, a2=0\n",
      ">10, d1=0.349, d2=0.854 g=0.580, a1=100, a2=0\n",
      ">11, d1=0.331, d2=0.876 g=0.577, a1=100, a2=0\n",
      ">12, d1=0.335, d2=0.863 g=0.594, a1=100, a2=0\n",
      ">13, d1=0.341, d2=0.822 g=0.631, a1=100, a2=0\n",
      ">14, d1=0.351, d2=0.769 g=0.683, a1=100, a2=0\n",
      ">15, d1=0.356, d2=0.705 g=0.747, a1=100, a2=1\n",
      ">16, d1=0.337, d2=0.636 g=0.826, a1=100, a2=100\n",
      ">17, d1=0.363, d2=0.573 g=0.913, a1=100, a2=100\n",
      ">18, d1=0.357, d2=0.508 g=1.012, a1=100, a2=100\n",
      ">19, d1=0.336, d2=0.447 g=1.120, a1=100, a2=100\n",
      ">20, d1=0.346, d2=0.393 g=1.234, a1=100, a2=100\n",
      ">21, d1=0.319, d2=0.342 g=1.357, a1=100, a2=100\n",
      ">22, d1=0.319, d2=0.298 g=1.478, a1=98, a2=100\n",
      ">23, d1=0.325, d2=0.263 g=1.585, a1=100, a2=100\n",
      ">24, d1=0.292, d2=0.233 g=1.697, a1=98, a2=100\n",
      ">25, d1=0.253, d2=0.206 g=1.815, a1=98, a2=100\n",
      ">26, d1=0.233, d2=0.180 g=1.935, a1=100, a2=100\n",
      ">27, d1=0.248, d2=0.161 g=2.028, a1=95, a2=100\n",
      ">28, d1=0.255, d2=0.150 g=2.094, a1=96, a2=100\n",
      ">29, d1=0.188, d2=0.136 g=2.190, a1=96, a2=100\n",
      ">30, d1=0.216, d2=0.126 g=2.257, a1=96, a2=100\n",
      ">31, d1=0.187, d2=0.117 g=2.320, a1=96, a2=100\n",
      ">32, d1=0.128, d2=0.106 g=2.432, a1=100, a2=100\n",
      ">33, d1=0.155, d2=0.097 g=2.508, a1=96, a2=100\n",
      ">34, d1=0.142, d2=0.090 g=2.578, a1=96, a2=100\n",
      ">35, d1=0.129, d2=0.083 g=2.648, a1=98, a2=100\n",
      ">36, d1=0.106, d2=0.076 g=2.736, a1=98, a2=100\n",
      ">37, d1=0.117, d2=0.071 g=2.794, a1=100, a2=100\n",
      ">38, d1=0.104, d2=0.067 g=2.862, a1=98, a2=100\n",
      ">39, d1=0.094, d2=0.062 g=2.933, a1=96, a2=100\n",
      ">40, d1=0.081, d2=0.057 g=3.011, a1=100, a2=100\n",
      ">41, d1=0.080, d2=0.053 g=3.078, a1=100, a2=100\n",
      ">42, d1=0.102, d2=0.051 g=3.096, a1=98, a2=100\n",
      ">43, d1=0.081, d2=0.050 g=3.130, a1=100, a2=100\n",
      ">44, d1=0.076, d2=0.048 g=3.175, a1=96, a2=100\n",
      ">45, d1=0.073, d2=0.046 g=3.223, a1=96, a2=100\n",
      ">46, d1=0.052, d2=0.042 g=3.307, a1=100, a2=100\n",
      ">47, d1=0.077, d2=0.041 g=3.324, a1=98, a2=100\n",
      ">48, d1=0.061, d2=0.039 g=3.377, a1=98, a2=100\n",
      ">49, d1=0.054, d2=0.036 g=3.438, a1=98, a2=100\n",
      ">50, d1=0.060, d2=0.035 g=3.463, a1=98, a2=100\n",
      ">51, d1=0.050, d2=0.034 g=3.513, a1=100, a2=100\n",
      ">52, d1=0.031, d2=0.031 g=3.614, a1=100, a2=100\n",
      ">53, d1=0.036, d2=0.028 g=3.690, a1=98, a2=100\n",
      ">54, d1=0.033, d2=0.026 g=3.761, a1=100, a2=100\n",
      ">55, d1=0.048, d2=0.025 g=3.781, a1=100, a2=100\n",
      ">56, d1=0.022, d2=0.023 g=3.867, a1=100, a2=100\n",
      ">57, d1=0.029, d2=0.022 g=3.931, a1=100, a2=100\n",
      ">58, d1=0.042, d2=0.022 g=3.943, a1=100, a2=100\n",
      ">59, d1=0.044, d2=0.022 g=3.936, a1=98, a2=100\n",
      ">60, d1=0.023, d2=0.020 g=3.997, a1=100, a2=100\n",
      ">61, d1=0.037, d2=0.020 g=3.985, a1=100, a2=100\n",
      ">62, d1=0.055, d2=0.023 g=3.946, a1=98, a2=100\n",
      ">63, d1=0.046, d2=0.024 g=3.894, a1=98, a2=100\n",
      ">64, d1=0.032, d2=0.034 g=3.925, a1=100, a2=100\n",
      ">65, d1=0.020, d2=0.023 g=3.988, a1=100, a2=100\n",
      ">66, d1=0.016, d2=0.084 g=4.140, a1=100, a2=96\n",
      ">67, d1=0.031, d2=0.124 g=4.074, a1=100, a2=95\n",
      ">68, d1=0.032, d2=0.194 g=3.625, a1=100, a2=93\n",
      ">69, d1=0.046, d2=0.363 g=1.576, a1=100, a2=84\n",
      ">70, d1=0.076, d2=1.582 g=0.300, a1=96, a2=0\n",
      ">71, d1=0.131, d2=2.401 g=0.227, a1=95, a2=0\n",
      ">72, d1=0.043, d2=1.969 g=0.361, a1=98, a2=0\n",
      ">73, d1=0.025, d2=1.182 g=0.646, a1=100, a2=20\n",
      ">74, d1=0.025, d2=0.707 g=0.957, a1=100, a2=59\n",
      ">75, d1=0.019, d2=0.542 g=1.078, a1=100, a2=84\n",
      ">76, d1=0.024, d2=0.483 g=1.047, a1=100, a2=100\n",
      ">77, d1=0.013, d2=0.507 g=0.972, a1=100, a2=100\n",
      ">78, d1=0.015, d2=0.543 g=0.895, a1=100, a2=100\n",
      ">79, d1=0.012, d2=0.581 g=0.838, a1=100, a2=100\n",
      ">80, d1=0.013, d2=0.630 g=0.773, a1=100, a2=100\n",
      ">81, d1=0.014, d2=0.711 g=0.707, a1=100, a2=31\n",
      ">82, d1=0.013, d2=0.752 g=0.664, a1=100, a2=26\n",
      ">83, d1=0.011, d2=0.746 g=0.695, a1=100, a2=31\n",
      ">84, d1=0.015, d2=0.736 g=0.697, a1=100, a2=35\n",
      ">85, d1=0.027, d2=0.724 g=0.712, a1=100, a2=35\n",
      ">86, d1=0.026, d2=0.721 g=0.734, a1=100, a2=35\n",
      ">87, d1=0.041, d2=0.711 g=0.709, a1=100, a2=32\n",
      ">88, d1=0.055, d2=0.698 g=0.727, a1=100, a2=37\n",
      ">89, d1=0.059, d2=0.686 g=0.722, a1=100, a2=46\n",
      ">90, d1=0.062, d2=0.699 g=0.712, a1=100, a2=43\n",
      ">91, d1=0.085, d2=0.728 g=0.706, a1=100, a2=21\n",
      ">92, d1=0.070, d2=0.734 g=0.696, a1=100, a2=28\n",
      ">93, d1=0.070, d2=0.733 g=0.723, a1=100, a2=26\n",
      ">94, d1=0.118, d2=0.752 g=0.703, a1=98, a2=14\n",
      ">95, d1=0.094, d2=0.752 g=0.723, a1=100, a2=15\n",
      ">96, d1=0.138, d2=0.769 g=0.706, a1=100, a2=15\n",
      ">97, d1=0.129, d2=0.762 g=0.730, a1=100, a2=21\n",
      ">98, d1=0.174, d2=0.789 g=0.756, a1=100, a2=9\n",
      ">99, d1=0.171, d2=0.732 g=0.792, a1=100, a2=29\n",
      ">100, d1=0.199, d2=0.738 g=0.832, a1=100, a2=29\n",
      ">101, d1=0.242, d2=0.706 g=0.835, a1=96, a2=45\n",
      ">102, d1=0.233, d2=0.722 g=0.844, a1=96, a2=37\n",
      ">103, d1=0.274, d2=0.746 g=0.850, a1=100, a2=25\n",
      ">104, d1=0.285, d2=0.773 g=0.834, a1=96, a2=28\n",
      ">105, d1=0.302, d2=0.766 g=0.851, a1=98, a2=28\n",
      ">106, d1=0.385, d2=0.759 g=0.846, a1=93, a2=29\n",
      ">107, d1=0.378, d2=0.763 g=0.823, a1=92, a2=35\n",
      ">108, d1=0.392, d2=0.810 g=0.859, a1=95, a2=32\n",
      ">109, d1=0.386, d2=0.775 g=0.874, a1=95, a2=32\n",
      ">110, d1=0.476, d2=0.809 g=0.878, a1=93, a2=26\n",
      ">111, d1=0.451, d2=0.796 g=0.970, a1=89, a2=32\n",
      ">112, d1=0.529, d2=0.709 g=0.919, a1=82, a2=51\n",
      ">113, d1=0.513, d2=0.774 g=0.882, a1=90, a2=31\n",
      ">114, d1=0.502, d2=0.784 g=0.944, a1=89, a2=23\n",
      ">115, d1=0.549, d2=0.712 g=0.945, a1=84, a2=53\n",
      ">116, d1=0.578, d2=0.757 g=0.942, a1=82, a2=34\n",
      ">117, d1=0.610, d2=0.741 g=0.921, a1=71, a2=34\n",
      ">118, d1=0.603, d2=0.735 g=0.953, a1=75, a2=37\n",
      ">119, d1=0.639, d2=0.714 g=0.925, a1=64, a2=43\n",
      ">120, d1=0.646, d2=0.719 g=0.904, a1=64, a2=35\n",
      ">121, d1=0.578, d2=0.727 g=0.922, a1=84, a2=37\n",
      ">122, d1=0.652, d2=0.714 g=0.946, a1=64, a2=48\n",
      ">123, d1=0.646, d2=0.705 g=0.921, a1=70, a2=40\n",
      ">124, d1=0.679, d2=0.729 g=0.915, a1=59, a2=28\n",
      ">125, d1=0.652, d2=0.702 g=0.933, a1=59, a2=48\n",
      ">126, d1=0.669, d2=0.697 g=0.937, a1=57, a2=48\n",
      ">127, d1=0.687, d2=0.700 g=0.921, a1=54, a2=40\n",
      ">128, d1=0.699, d2=0.681 g=0.911, a1=51, a2=54\n",
      ">129, d1=0.684, d2=0.690 g=0.909, a1=53, a2=50\n",
      ">130, d1=0.672, d2=0.694 g=0.913, a1=57, a2=53\n",
      ">131, d1=0.705, d2=0.703 g=0.919, a1=50, a2=45\n",
      ">132, d1=0.687, d2=0.689 g=0.914, a1=62, a2=62\n",
      ">133, d1=0.740, d2=0.686 g=0.916, a1=35, a2=51\n",
      ">134, d1=0.705, d2=0.697 g=0.899, a1=54, a2=43\n",
      ">135, d1=0.658, d2=0.677 g=0.916, a1=68, a2=62\n",
      ">136, d1=0.730, d2=0.667 g=0.895, a1=43, a2=60\n",
      ">137, d1=0.721, d2=0.695 g=0.891, a1=51, a2=57\n",
      ">138, d1=0.677, d2=0.692 g=0.881, a1=59, a2=53\n",
      ">139, d1=0.709, d2=0.687 g=0.877, a1=50, a2=57\n",
      ">140, d1=0.741, d2=0.725 g=0.863, a1=50, a2=32\n",
      ">141, d1=0.701, d2=0.694 g=0.880, a1=50, a2=54\n",
      ">142, d1=0.692, d2=0.692 g=0.882, a1=56, a2=53\n",
      ">143, d1=0.722, d2=0.673 g=0.861, a1=48, a2=68\n",
      ">144, d1=0.718, d2=0.714 g=0.868, a1=53, a2=40\n",
      ">145, d1=0.706, d2=0.719 g=0.863, a1=60, a2=37\n",
      ">146, d1=0.749, d2=0.702 g=0.857, a1=43, a2=59\n",
      ">147, d1=0.699, d2=0.695 g=0.858, a1=50, a2=57\n",
      ">148, d1=0.734, d2=0.681 g=0.847, a1=46, a2=60\n",
      ">149, d1=0.720, d2=0.680 g=0.873, a1=48, a2=57\n",
      ">150, d1=0.711, d2=0.702 g=0.829, a1=50, a2=50\n",
      ">151, d1=0.693, d2=0.692 g=0.847, a1=54, a2=51\n",
      ">152, d1=0.728, d2=0.695 g=0.838, a1=56, a2=54\n",
      ">153, d1=0.723, d2=0.672 g=0.835, a1=54, a2=59\n",
      ">154, d1=0.702, d2=0.709 g=0.850, a1=50, a2=48\n",
      ">155, d1=0.676, d2=0.694 g=0.837, a1=64, a2=53\n",
      ">156, d1=0.690, d2=0.671 g=0.861, a1=54, a2=62\n",
      ">157, d1=0.694, d2=0.671 g=0.836, a1=57, a2=57\n",
      ">158, d1=0.710, d2=0.694 g=0.836, a1=43, a2=51\n",
      ">159, d1=0.675, d2=0.689 g=0.823, a1=59, a2=50\n",
      ">160, d1=0.692, d2=0.705 g=0.836, a1=56, a2=48\n",
      ">161, d1=0.675, d2=0.670 g=0.855, a1=62, a2=64\n",
      ">162, d1=0.694, d2=0.652 g=0.845, a1=57, a2=75\n",
      ">163, d1=0.692, d2=0.660 g=0.853, a1=56, a2=59\n",
      ">164, d1=0.682, d2=0.663 g=0.856, a1=53, a2=65\n",
      ">165, d1=0.657, d2=0.667 g=0.869, a1=59, a2=65\n",
      ">166, d1=0.715, d2=0.650 g=0.861, a1=48, a2=71\n",
      ">167, d1=0.756, d2=0.677 g=0.848, a1=46, a2=56\n",
      ">168, d1=0.655, d2=0.663 g=0.854, a1=62, a2=70\n",
      ">169, d1=0.720, d2=0.680 g=0.846, a1=48, a2=56\n",
      ">170, d1=0.637, d2=0.662 g=0.874, a1=68, a2=68\n",
      ">171, d1=0.679, d2=0.645 g=0.868, a1=62, a2=81\n",
      ">172, d1=0.673, d2=0.653 g=0.879, a1=57, a2=68\n",
      ">173, d1=0.692, d2=0.639 g=0.875, a1=57, a2=81\n",
      ">174, d1=0.686, d2=0.651 g=0.852, a1=56, a2=79\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">175, d1=0.644, d2=0.658 g=0.878, a1=62, a2=73\n",
      ">176, d1=0.702, d2=0.655 g=0.865, a1=50, a2=75\n",
      ">177, d1=0.652, d2=0.645 g=0.856, a1=70, a2=79\n",
      ">178, d1=0.719, d2=0.649 g=0.854, a1=51, a2=76\n",
      ">179, d1=0.668, d2=0.653 g=0.865, a1=56, a2=76\n",
      ">180, d1=0.707, d2=0.653 g=0.846, a1=53, a2=73\n",
      ">181, d1=0.671, d2=0.673 g=0.842, a1=57, a2=65\n",
      ">182, d1=0.682, d2=0.655 g=0.834, a1=53, a2=67\n",
      ">183, d1=0.648, d2=0.668 g=0.852, a1=73, a2=67\n",
      ">184, d1=0.699, d2=0.653 g=0.847, a1=51, a2=71\n",
      ">185, d1=0.753, d2=0.661 g=0.837, a1=46, a2=68\n",
      ">186, d1=0.662, d2=0.652 g=0.838, a1=64, a2=70\n",
      ">187, d1=0.701, d2=0.676 g=0.836, a1=57, a2=57\n",
      ">188, d1=0.638, d2=0.677 g=0.834, a1=65, a2=60\n",
      ">189, d1=0.660, d2=0.643 g=0.848, a1=54, a2=71\n",
      ">190, d1=0.688, d2=0.678 g=0.860, a1=54, a2=60\n",
      ">191, d1=0.717, d2=0.682 g=0.830, a1=46, a2=50\n",
      ">192, d1=0.694, d2=0.663 g=0.807, a1=54, a2=65\n",
      ">193, d1=0.672, d2=0.693 g=0.818, a1=65, a2=51\n",
      ">194, d1=0.709, d2=0.720 g=0.800, a1=56, a2=35\n",
      ">195, d1=0.718, d2=0.720 g=0.812, a1=53, a2=50\n",
      ">196, d1=0.699, d2=0.717 g=0.826, a1=59, a2=45\n",
      ">197, d1=0.726, d2=0.680 g=0.805, a1=42, a2=59\n",
      ">198, d1=0.783, d2=0.706 g=0.785, a1=39, a2=43\n",
      ">199, d1=0.725, d2=0.719 g=0.787, a1=51, a2=45\n",
      ">200, d1=0.733, d2=0.726 g=0.766, a1=48, a2=39\n",
      ">201, d1=0.734, d2=0.738 g=0.773, a1=54, a2=26\n",
      ">202, d1=0.754, d2=0.712 g=0.760, a1=34, a2=42\n",
      ">203, d1=0.767, d2=0.724 g=0.764, a1=37, a2=45\n",
      ">204, d1=0.736, d2=0.770 g=0.732, a1=43, a2=35\n",
      ">205, d1=0.779, d2=0.755 g=0.746, a1=35, a2=28\n",
      ">206, d1=0.780, d2=0.754 g=0.747, a1=35, a2=34\n",
      ">207, d1=0.780, d2=0.760 g=0.729, a1=26, a2=28\n",
      ">208, d1=0.740, d2=0.720 g=0.721, a1=40, a2=45\n",
      ">209, d1=0.748, d2=0.768 g=0.739, a1=32, a2=37\n",
      ">210, d1=0.748, d2=0.755 g=0.731, a1=42, a2=31\n",
      ">211, d1=0.768, d2=0.753 g=0.727, a1=40, a2=35\n",
      ">212, d1=0.752, d2=0.780 g=0.735, a1=37, a2=28\n",
      ">213, d1=0.761, d2=0.727 g=0.749, a1=34, a2=43\n",
      ">214, d1=0.789, d2=0.764 g=0.707, a1=31, a2=31\n",
      ">215, d1=0.738, d2=0.780 g=0.735, a1=37, a2=31\n",
      ">216, d1=0.792, d2=0.757 g=0.711, a1=23, a2=37\n",
      ">217, d1=0.747, d2=0.750 g=0.742, a1=39, a2=39\n",
      ">218, d1=0.779, d2=0.773 g=0.720, a1=21, a2=21\n",
      ">219, d1=0.747, d2=0.769 g=0.726, a1=34, a2=29\n",
      ">220, d1=0.748, d2=0.758 g=0.726, a1=39, a2=26\n",
      ">221, d1=0.800, d2=0.761 g=0.718, a1=15, a2=35\n",
      ">222, d1=0.743, d2=0.752 g=0.724, a1=35, a2=35\n",
      ">223, d1=0.763, d2=0.793 g=0.742, a1=29, a2=23\n",
      ">224, d1=0.775, d2=0.774 g=0.743, a1=20, a2=21\n",
      ">225, d1=0.767, d2=0.736 g=0.725, a1=21, a2=34\n",
      ">226, d1=0.787, d2=0.748 g=0.728, a1=20, a2=29\n",
      ">227, d1=0.776, d2=0.747 g=0.725, a1=23, a2=34\n",
      ">228, d1=0.735, d2=0.758 g=0.710, a1=39, a2=20\n",
      ">229, d1=0.744, d2=0.742 g=0.719, a1=26, a2=32\n",
      ">230, d1=0.733, d2=0.745 g=0.748, a1=34, a2=32\n",
      ">231, d1=0.754, d2=0.754 g=0.720, a1=25, a2=28\n",
      ">232, d1=0.757, d2=0.745 g=0.730, a1=29, a2=29\n",
      ">233, d1=0.745, d2=0.712 g=0.733, a1=32, a2=42\n",
      ">234, d1=0.736, d2=0.730 g=0.732, a1=35, a2=31\n",
      ">235, d1=0.733, d2=0.726 g=0.743, a1=34, a2=43\n",
      ">236, d1=0.767, d2=0.724 g=0.731, a1=23, a2=32\n",
      ">237, d1=0.747, d2=0.727 g=0.748, a1=29, a2=29\n",
      ">238, d1=0.738, d2=0.700 g=0.748, a1=39, a2=48\n",
      ">239, d1=0.751, d2=0.691 g=0.742, a1=39, a2=50\n",
      ">240, d1=0.734, d2=0.704 g=0.753, a1=40, a2=48\n",
      ">241, d1=0.745, d2=0.711 g=0.750, a1=37, a2=42\n",
      ">242, d1=0.732, d2=0.722 g=0.748, a1=42, a2=35\n",
      ">243, d1=0.693, d2=0.707 g=0.764, a1=57, a2=46\n",
      ">244, d1=0.737, d2=0.712 g=0.769, a1=37, a2=40\n",
      ">245, d1=0.747, d2=0.692 g=0.769, a1=31, a2=56\n",
      ">246, d1=0.715, d2=0.701 g=0.769, a1=40, a2=48\n",
      ">247, d1=0.704, d2=0.702 g=0.764, a1=43, a2=45\n",
      ">248, d1=0.717, d2=0.692 g=0.776, a1=45, a2=51\n",
      ">249, d1=0.713, d2=0.701 g=0.767, a1=40, a2=46\n",
      ">250, d1=0.703, d2=0.705 g=0.766, a1=45, a2=45\n",
      ">251, d1=0.710, d2=0.689 g=0.760, a1=39, a2=57\n",
      ">252, d1=0.686, d2=0.685 g=0.767, a1=50, a2=54\n",
      ">253, d1=0.723, d2=0.690 g=0.767, a1=43, a2=48\n",
      ">254, d1=0.696, d2=0.685 g=0.756, a1=53, a2=51\n",
      ">255, d1=0.696, d2=0.701 g=0.766, a1=56, a2=39\n",
      ">256, d1=0.704, d2=0.696 g=0.771, a1=50, a2=48\n",
      ">257, d1=0.714, d2=0.698 g=0.766, a1=50, a2=51\n",
      ">258, d1=0.705, d2=0.681 g=0.768, a1=46, a2=57\n",
      ">259, d1=0.719, d2=0.677 g=0.756, a1=40, a2=67\n",
      ">260, d1=0.725, d2=0.690 g=0.768, a1=40, a2=50\n",
      ">261, d1=0.708, d2=0.706 g=0.760, a1=50, a2=51\n",
      ">262, d1=0.675, d2=0.692 g=0.749, a1=57, a2=56\n",
      ">263, d1=0.677, d2=0.692 g=0.763, a1=60, a2=51\n",
      ">264, d1=0.700, d2=0.712 g=0.763, a1=51, a2=45\n",
      ">265, d1=0.704, d2=0.696 g=0.755, a1=48, a2=48\n",
      ">266, d1=0.679, d2=0.697 g=0.749, a1=64, a2=50\n",
      ">267, d1=0.692, d2=0.691 g=0.745, a1=45, a2=50\n",
      ">268, d1=0.709, d2=0.701 g=0.755, a1=45, a2=45\n",
      ">269, d1=0.704, d2=0.700 g=0.753, a1=43, a2=46\n",
      ">270, d1=0.718, d2=0.704 g=0.764, a1=45, a2=50\n",
      ">271, d1=0.698, d2=0.695 g=0.750, a1=48, a2=45\n",
      ">272, d1=0.739, d2=0.680 g=0.762, a1=40, a2=53\n",
      ">273, d1=0.707, d2=0.691 g=0.755, a1=45, a2=51\n",
      ">274, d1=0.727, d2=0.711 g=0.768, a1=42, a2=37\n",
      ">275, d1=0.707, d2=0.704 g=0.756, a1=46, a2=50\n",
      ">276, d1=0.721, d2=0.696 g=0.759, a1=40, a2=48\n",
      ">277, d1=0.734, d2=0.704 g=0.757, a1=40, a2=43\n",
      ">278, d1=0.721, d2=0.732 g=0.743, a1=40, a2=40\n",
      ">279, d1=0.707, d2=0.702 g=0.741, a1=45, a2=53\n",
      ">280, d1=0.731, d2=0.717 g=0.742, a1=39, a2=37\n",
      ">281, d1=0.729, d2=0.703 g=0.741, a1=31, a2=43\n",
      ">282, d1=0.707, d2=0.704 g=0.746, a1=48, a2=48\n",
      ">283, d1=0.726, d2=0.711 g=0.755, a1=39, a2=42\n",
      ">284, d1=0.720, d2=0.700 g=0.735, a1=42, a2=45\n",
      ">285, d1=0.721, d2=0.710 g=0.740, a1=32, a2=40\n",
      ">286, d1=0.743, d2=0.724 g=0.725, a1=29, a2=35\n",
      ">287, d1=0.726, d2=0.729 g=0.737, a1=45, a2=34\n",
      ">288, d1=0.719, d2=0.727 g=0.739, a1=40, a2=32\n",
      ">289, d1=0.731, d2=0.713 g=0.733, a1=31, a2=37\n",
      ">290, d1=0.724, d2=0.712 g=0.718, a1=40, a2=46\n",
      ">291, d1=0.733, d2=0.749 g=0.716, a1=35, a2=26\n",
      ">292, d1=0.740, d2=0.724 g=0.712, a1=34, a2=34\n",
      ">293, d1=0.738, d2=0.727 g=0.703, a1=31, a2=32\n",
      ">294, d1=0.743, d2=0.727 g=0.722, a1=34, a2=35\n",
      ">295, d1=0.753, d2=0.735 g=0.703, a1=26, a2=34\n",
      ">296, d1=0.743, d2=0.762 g=0.691, a1=31, a2=17\n",
      ">297, d1=0.724, d2=0.747 g=0.708, a1=35, a2=25\n",
      ">298, d1=0.736, d2=0.754 g=0.702, a1=42, a2=23\n",
      ">299, d1=0.763, d2=0.741 g=0.682, a1=23, a2=25\n",
      ">300, d1=0.749, d2=0.745 g=0.698, a1=29, a2=26\n",
      ">301, d1=0.750, d2=0.769 g=0.688, a1=28, a2=18\n",
      ">302, d1=0.741, d2=0.780 g=0.683, a1=32, a2=20\n",
      ">303, d1=0.771, d2=0.763 g=0.689, a1=20, a2=15\n",
      ">304, d1=0.786, d2=0.759 g=0.689, a1=14, a2=20\n",
      ">305, d1=0.761, d2=0.770 g=0.704, a1=23, a2=9\n",
      ">306, d1=0.760, d2=0.756 g=0.693, a1=18, a2=18\n",
      ">307, d1=0.779, d2=0.753 g=0.697, a1=21, a2=20\n",
      ">308, d1=0.758, d2=0.753 g=0.703, a1=20, a2=21\n",
      ">309, d1=0.778, d2=0.731 g=0.699, a1=17, a2=25\n",
      ">310, d1=0.771, d2=0.750 g=0.693, a1=17, a2=12\n",
      ">311, d1=0.766, d2=0.745 g=0.695, a1=20, a2=25\n",
      ">312, d1=0.771, d2=0.723 g=0.706, a1=12, a2=35\n",
      ">313, d1=0.787, d2=0.744 g=0.696, a1=17, a2=15\n",
      ">314, d1=0.766, d2=0.744 g=0.709, a1=20, a2=15\n",
      ">315, d1=0.765, d2=0.732 g=0.710, a1=17, a2=14\n",
      ">316, d1=0.769, d2=0.731 g=0.711, a1=9, a2=23\n",
      ">317, d1=0.766, d2=0.727 g=0.717, a1=20, a2=25\n",
      ">318, d1=0.756, d2=0.723 g=0.712, a1=21, a2=21\n",
      ">319, d1=0.764, d2=0.727 g=0.715, a1=12, a2=20\n",
      ">320, d1=0.760, d2=0.722 g=0.720, a1=21, a2=32\n",
      ">321, d1=0.761, d2=0.717 g=0.718, a1=23, a2=26\n",
      ">322, d1=0.736, d2=0.710 g=0.724, a1=29, a2=37\n",
      ">323, d1=0.759, d2=0.720 g=0.727, a1=25, a2=25\n",
      ">324, d1=0.750, d2=0.707 g=0.726, a1=28, a2=39\n",
      ">325, d1=0.758, d2=0.696 g=0.732, a1=26, a2=48\n",
      ">326, d1=0.750, d2=0.711 g=0.729, a1=28, a2=37\n",
      ">327, d1=0.752, d2=0.705 g=0.727, a1=21, a2=43\n",
      ">328, d1=0.763, d2=0.711 g=0.731, a1=18, a2=39\n",
      ">329, d1=0.746, d2=0.705 g=0.732, a1=25, a2=43\n",
      ">330, d1=0.748, d2=0.706 g=0.733, a1=26, a2=40\n",
      ">331, d1=0.757, d2=0.694 g=0.732, a1=23, a2=51\n",
      ">332, d1=0.760, d2=0.693 g=0.736, a1=26, a2=51\n",
      ">333, d1=0.738, d2=0.709 g=0.733, a1=29, a2=37\n",
      ">334, d1=0.739, d2=0.688 g=0.732, a1=28, a2=57\n",
      ">335, d1=0.746, d2=0.707 g=0.742, a1=25, a2=43\n",
      ">336, d1=0.753, d2=0.703 g=0.723, a1=18, a2=43\n",
      ">337, d1=0.737, d2=0.704 g=0.736, a1=31, a2=42\n",
      ">338, d1=0.740, d2=0.702 g=0.723, a1=21, a2=45\n",
      ">339, d1=0.735, d2=0.705 g=0.735, a1=20, a2=50\n",
      ">340, d1=0.743, d2=0.706 g=0.729, a1=26, a2=46\n",
      ">341, d1=0.746, d2=0.703 g=0.737, a1=32, a2=45\n",
      ">342, d1=0.750, d2=0.700 g=0.741, a1=25, a2=48\n",
      ">343, d1=0.746, d2=0.712 g=0.730, a1=25, a2=34\n",
      ">344, d1=0.749, d2=0.708 g=0.726, a1=18, a2=45\n",
      ">345, d1=0.748, d2=0.710 g=0.728, a1=21, a2=40\n",
      ">346, d1=0.736, d2=0.707 g=0.738, a1=29, a2=46\n",
      ">347, d1=0.737, d2=0.693 g=0.723, a1=29, a2=50\n",
      ">348, d1=0.752, d2=0.714 g=0.724, a1=23, a2=37\n",
      ">349, d1=0.738, d2=0.720 g=0.729, a1=26, a2=28\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">350, d1=0.749, d2=0.716 g=0.718, a1=28, a2=42\n",
      ">351, d1=0.760, d2=0.706 g=0.710, a1=21, a2=46\n",
      ">352, d1=0.749, d2=0.728 g=0.714, a1=28, a2=32\n",
      ">353, d1=0.733, d2=0.717 g=0.717, a1=29, a2=35\n",
      ">354, d1=0.740, d2=0.710 g=0.717, a1=25, a2=42\n",
      ">355, d1=0.743, d2=0.717 g=0.715, a1=28, a2=42\n",
      ">356, d1=0.749, d2=0.709 g=0.719, a1=21, a2=42\n",
      ">357, d1=0.740, d2=0.717 g=0.697, a1=26, a2=39\n",
      ">358, d1=0.748, d2=0.724 g=0.731, a1=18, a2=31\n",
      ">359, d1=0.736, d2=0.714 g=0.713, a1=32, a2=40\n",
      ">360, d1=0.736, d2=0.739 g=0.712, a1=25, a2=31\n",
      ">361, d1=0.736, d2=0.728 g=0.714, a1=25, a2=34\n",
      ">362, d1=0.755, d2=0.713 g=0.712, a1=15, a2=37\n",
      ">363, d1=0.755, d2=0.722 g=0.715, a1=15, a2=34\n",
      ">364, d1=0.742, d2=0.720 g=0.709, a1=28, a2=32\n",
      ">365, d1=0.729, d2=0.723 g=0.721, a1=29, a2=35\n",
      ">366, d1=0.746, d2=0.719 g=0.715, a1=26, a2=39\n",
      ">367, d1=0.752, d2=0.714 g=0.725, a1=20, a2=40\n",
      ">368, d1=0.745, d2=0.724 g=0.711, a1=25, a2=32\n",
      ">369, d1=0.748, d2=0.705 g=0.700, a1=20, a2=50\n",
      ">370, d1=0.736, d2=0.720 g=0.717, a1=26, a2=43\n",
      ">371, d1=0.741, d2=0.729 g=0.716, a1=28, a2=31\n",
      ">372, d1=0.749, d2=0.733 g=0.710, a1=18, a2=25\n",
      ">373, d1=0.743, d2=0.722 g=0.707, a1=17, a2=35\n",
      ">374, d1=0.747, d2=0.720 g=0.717, a1=23, a2=35\n",
      ">375, d1=0.744, d2=0.721 g=0.717, a1=15, a2=39\n",
      ">376, d1=0.739, d2=0.709 g=0.714, a1=21, a2=43\n",
      ">377, d1=0.724, d2=0.704 g=0.731, a1=32, a2=48\n",
      ">378, d1=0.748, d2=0.736 g=0.717, a1=21, a2=23\n",
      ">379, d1=0.740, d2=0.716 g=0.721, a1=23, a2=37\n",
      ">380, d1=0.741, d2=0.701 g=0.717, a1=17, a2=54\n",
      ">381, d1=0.752, d2=0.702 g=0.727, a1=17, a2=45\n",
      ">382, d1=0.743, d2=0.715 g=0.718, a1=21, a2=43\n",
      ">383, d1=0.748, d2=0.705 g=0.721, a1=18, a2=43\n",
      ">384, d1=0.744, d2=0.699 g=0.707, a1=18, a2=42\n",
      ">385, d1=0.724, d2=0.715 g=0.715, a1=28, a2=46\n",
      ">386, d1=0.716, d2=0.716 g=0.729, a1=34, a2=37\n",
      ">387, d1=0.728, d2=0.711 g=0.717, a1=28, a2=42\n",
      ">388, d1=0.737, d2=0.711 g=0.723, a1=23, a2=40\n",
      ">389, d1=0.709, d2=0.693 g=0.717, a1=42, a2=60\n",
      ">390, d1=0.714, d2=0.717 g=0.720, a1=37, a2=39\n",
      ">391, d1=0.709, d2=0.720 g=0.724, a1=34, a2=39\n",
      ">392, d1=0.725, d2=0.706 g=0.712, a1=28, a2=42\n",
      ">393, d1=0.725, d2=0.713 g=0.720, a1=34, a2=42\n",
      ">394, d1=0.735, d2=0.694 g=0.707, a1=18, a2=50\n",
      ">395, d1=0.714, d2=0.711 g=0.704, a1=37, a2=35\n",
      ">396, d1=0.714, d2=0.714 g=0.718, a1=39, a2=42\n",
      ">397, d1=0.716, d2=0.718 g=0.723, a1=35, a2=35\n",
      ">398, d1=0.716, d2=0.696 g=0.708, a1=35, a2=57\n",
      ">399, d1=0.710, d2=0.702 g=0.736, a1=37, a2=48\n",
      ">400, d1=0.722, d2=0.718 g=0.714, a1=34, a2=35\n",
      ">401, d1=0.717, d2=0.699 g=0.731, a1=37, a2=46\n",
      ">402, d1=0.709, d2=0.704 g=0.725, a1=42, a2=45\n",
      ">403, d1=0.725, d2=0.723 g=0.732, a1=32, a2=29\n",
      ">404, d1=0.734, d2=0.706 g=0.726, a1=17, a2=43\n",
      ">405, d1=0.718, d2=0.709 g=0.726, a1=35, a2=42\n",
      ">406, d1=0.729, d2=0.686 g=0.724, a1=34, a2=54\n",
      ">407, d1=0.724, d2=0.698 g=0.718, a1=28, a2=48\n",
      ">408, d1=0.725, d2=0.710 g=0.718, a1=28, a2=37\n",
      ">409, d1=0.721, d2=0.711 g=0.719, a1=28, a2=45\n",
      ">410, d1=0.708, d2=0.707 g=0.722, a1=40, a2=45\n",
      ">411, d1=0.728, d2=0.699 g=0.725, a1=29, a2=54\n",
      ">412, d1=0.713, d2=0.718 g=0.725, a1=35, a2=35\n",
      ">413, d1=0.722, d2=0.710 g=0.726, a1=29, a2=42\n",
      ">414, d1=0.713, d2=0.699 g=0.722, a1=34, a2=46\n",
      ">415, d1=0.725, d2=0.704 g=0.732, a1=23, a2=45\n",
      ">416, d1=0.723, d2=0.715 g=0.722, a1=29, a2=35\n",
      ">417, d1=0.712, d2=0.697 g=0.725, a1=32, a2=46\n",
      ">418, d1=0.713, d2=0.688 g=0.722, a1=31, a2=56\n",
      ">419, d1=0.731, d2=0.687 g=0.719, a1=31, a2=64\n",
      ">420, d1=0.705, d2=0.710 g=0.722, a1=43, a2=37\n",
      ">421, d1=0.720, d2=0.701 g=0.725, a1=29, a2=48\n",
      ">422, d1=0.710, d2=0.690 g=0.725, a1=35, a2=56\n",
      ">423, d1=0.708, d2=0.683 g=0.730, a1=37, a2=64\n",
      ">424, d1=0.724, d2=0.695 g=0.713, a1=35, a2=53\n",
      ">425, d1=0.704, d2=0.716 g=0.721, a1=43, a2=32\n",
      ">426, d1=0.708, d2=0.695 g=0.726, a1=34, a2=54\n",
      ">427, d1=0.714, d2=0.700 g=0.730, a1=39, a2=50\n",
      ">428, d1=0.718, d2=0.704 g=0.723, a1=29, a2=43\n",
      ">429, d1=0.712, d2=0.695 g=0.735, a1=45, a2=51\n",
      ">430, d1=0.723, d2=0.699 g=0.732, a1=28, a2=50\n",
      ">431, d1=0.720, d2=0.715 g=0.729, a1=28, a2=35\n",
      ">432, d1=0.721, d2=0.705 g=0.721, a1=25, a2=53\n",
      ">433, d1=0.727, d2=0.699 g=0.728, a1=21, a2=53\n",
      ">434, d1=0.722, d2=0.701 g=0.731, a1=21, a2=51\n",
      ">435, d1=0.726, d2=0.695 g=0.719, a1=23, a2=51\n",
      ">436, d1=0.711, d2=0.703 g=0.729, a1=37, a2=45\n",
      ">437, d1=0.715, d2=0.690 g=0.731, a1=37, a2=57\n",
      ">438, d1=0.714, d2=0.699 g=0.729, a1=34, a2=53\n",
      ">439, d1=0.721, d2=0.695 g=0.724, a1=35, a2=53\n",
      ">440, d1=0.723, d2=0.702 g=0.727, a1=25, a2=45\n",
      ">441, d1=0.718, d2=0.696 g=0.720, a1=28, a2=48\n",
      ">442, d1=0.707, d2=0.700 g=0.723, a1=37, a2=53\n",
      ">443, d1=0.713, d2=0.708 g=0.720, a1=32, a2=42\n",
      ">444, d1=0.712, d2=0.702 g=0.735, a1=34, a2=45\n",
      ">445, d1=0.716, d2=0.706 g=0.726, a1=28, a2=37\n",
      ">446, d1=0.720, d2=0.694 g=0.727, a1=23, a2=51\n",
      ">447, d1=0.721, d2=0.701 g=0.731, a1=21, a2=43\n",
      ">448, d1=0.724, d2=0.697 g=0.735, a1=26, a2=45\n",
      ">449, d1=0.728, d2=0.701 g=0.736, a1=21, a2=45\n",
      ">450, d1=0.726, d2=0.698 g=0.724, a1=26, a2=53\n"
     ]
    }
   ],
   "source": [
    "# example of training a stable gan for generating a handwritten digit\n",
    "import tensorflow as tf\n",
    "from os import makedirs\n",
    "from numpy import expand_dims\n",
    "from numpy import zeros\n",
    "from numpy import ones\n",
    "from numpy.random import randn\n",
    "from numpy.random import randint\n",
    "from tensorflow.keras.datasets.mnist import load_data\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Reshape\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Conv2DTranspose\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.initializers import RandomNormal\n",
    "from matplotlib import pyplot\n",
    "# define the standalone discriminator model\n",
    "def define_discriminator(in_shape=(28,28,1)):\n",
    "# weight initialization\n",
    " init = RandomNormal(stddev=0.02)\n",
    "# define model\n",
    " model = Sequential()\n",
    "# downsample to 14x14\n",
    " model.add(Conv2D(64, (4,4), strides=(2,2), padding='same', kernel_initializer=init, input_shape=in_shape))\n",
    " model.add(LeakyReLU(alpha=0.2))\n",
    "# downsample to 7x7\n",
    " model.add(Conv2D(64, (4,4), strides=(2,2), padding='same', kernel_initializer=init))\n",
    " \n",
    " model.add(LeakyReLU(alpha=0.2))\n",
    "# classifier\n",
    " model.add(Flatten())\n",
    " model.add(Dense(1, activation='sigmoid'))\n",
    "# compile model\n",
    " opt = Adam(lr=0.0002, beta_1=0.5)\n",
    " model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    " return model\n",
    "# define the standalone generator model\n",
    "def define_generator(latent_dim):\n",
    "# weight initialization\n",
    " init = RandomNormal(stddev=0.02)\n",
    "# define model\n",
    " model = Sequential()\n",
    "# foundation for 7x7 image\n",
    " n_nodes = 128 * 7 * 7\n",
    " model.add(Dense(n_nodes, kernel_initializer=init, input_dim=latent_dim))\n",
    " model.add(LeakyReLU(alpha=0.2))\n",
    " model.add(Reshape((7, 7, 128)))\n",
    "# upsample to 14x14\n",
    " model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same',kernel_initializer=init))\n",
    " \n",
    " model.add(LeakyReLU(alpha=0.2))\n",
    "# upsample to 28x28\n",
    " model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same',kernel_initializer=init))\n",
    " \n",
    " model.add(LeakyReLU(alpha=0.2))\n",
    "# output 28x28x1\n",
    " model.add(Conv2D(1, (7,7), activation='tanh', padding='same', kernel_initializer=init))\n",
    " return model\n",
    "# define the combined generator and discriminator model, for updating the generator\n",
    "def define_gan(generator, discriminator):\n",
    "# make weights in the discriminator not trainable\n",
    " discriminator.trainable = False\n",
    "# connect them\n",
    " model = Sequential()\n",
    "# add generator\n",
    " model.add(generator)\n",
    "# add the discriminator\n",
    " model.add(discriminator)\n",
    "# compile model\n",
    " opt = Adam(lr=0.0002, beta_1=0.5)\n",
    " model.compile(loss='binary_crossentropy', optimizer=opt)\n",
    " return model\n",
    "# load mnist images\n",
    "def load_real_samples():\n",
    "# load dataset\n",
    " (trainX, trainy), (_, _) = load_data()\n",
    "# expand to 3d, e.g. add channels\n",
    " X = expand_dims(trainX, axis=-1)\n",
    "# select all of the examples for a given class\n",
    " selected_ix = trainy == 8\n",
    " X = X[selected_ix]\n",
    "# convert from ints to floats\n",
    " X = X.astype('float32')\n",
    "# scale from [0,255] to [-1,1]\n",
    " X = (X - 127.5) / 127.5\n",
    " return X\n",
    "# select real samples\n",
    "def generate_real_samples(dataset, n_samples):\n",
    "# choose random instances\n",
    " ix = randint(0, dataset.shape[0], n_samples)\n",
    "# select images\n",
    " X = dataset[ix]\n",
    "# generate class labels\n",
    " y = ones((n_samples, 1))\n",
    " return X, y\n",
    "# generate points in latent space as input for the generator\n",
    "def generate_latent_points(latent_dim, n_samples):\n",
    "# generate points in the latent spac\n",
    " x_input = randn(latent_dim * n_samples)\n",
    "# reshape into a batch of inputs for the network\n",
    " x_input = x_input.reshape(n_samples, latent_dim)\n",
    " return x_input\n",
    "# use the generator to generate n fake examples, with class labels\n",
    "def generate_fake_samples(generator, latent_dim, n_samples):\n",
    "# generate points in latent space\n",
    " x_input = generate_latent_points(latent_dim, n_samples)\n",
    "# predict outputs\n",
    " X = generator.predict(x_input)\n",
    "# create class labels\n",
    " y = zeros((n_samples, 1))\n",
    " return X, y\n",
    "# generate samples and save as a plot and save the model\n",
    "def summarize_performance(step, g_model, latent_dim, n_samples=100):\n",
    "# prepare fake examples\n",
    " X, _ = generate_fake_samples(g_model, latent_dim, n_samples)\n",
    "# scale from [-1,1] to [0,1]\n",
    " X = (X + 1) / 2.0\n",
    "# plot images\n",
    " for i in range(10 * 10):\n",
    "# define subplot\n",
    "  pyplot.subplot(10, 10, 1 + i)\n",
    "# turn off axis\n",
    "  pyplot.axis('off')\n",
    "# plot raw pixel data\n",
    "  pyplot.imshow(X[i, :, :, 0], cmap='gray_r')\n",
    "# save plot to file\n",
    " pyplot.savefig('results_baseline/generated_plot_%03d.png' % (step+1))\n",
    " pyplot.close()\n",
    "# save the generator model\n",
    " g_model.save('results_baseline/model_%03d.h5' % (step+1))\n",
    "# create a line plot of loss for the gan and save to file\n",
    "def plot_history(d1_hist, d2_hist, g_hist, a1_hist, a2_hist):\n",
    "# plot loss\n",
    " pyplot.subplot(2, 1, 1)\n",
    " pyplot.plot(d1_hist, label='d-real')\n",
    " pyplot.plot(d2_hist, label='d-fake')\n",
    " pyplot.plot(g_hist, label='gen')\n",
    " pyplot.legend()\n",
    "# plot discriminator accuracy\n",
    " pyplot.subplot(2, 1, 2)\n",
    " pyplot.plot(a1_hist, label='acc-real')\n",
    " pyplot.plot(a2_hist, label='acc-fake')\n",
    " pyplot.legend()\n",
    "# save plot to file\n",
    " pyplot.savefig('results_baseline/plot_line_plot_loss.png')\n",
    " pyplot.close()\n",
    "# train the generator and discriminator\n",
    "def train(g_model, d_model, gan_model, dataset, latent_dim, n_epochs=10, n_batch=128):\n",
    "# calculate the number of batches per epoch\n",
    " bat_per_epo = int(dataset.shape[0] / n_batch)\n",
    "# calculate the total iterations based on batch and epoch\n",
    " n_steps = bat_per_epo * n_epochs\n",
    "# calculate the number of samples in half a batch\n",
    " half_batch = int(n_batch / 2)\n",
    "# prepare lists for storing stats each iteration\n",
    " d1_hist, d2_hist, g_hist, a1_hist, a2_hist = list(), list(), list(), list(), list()\n",
    "# manually enumerate epochs\n",
    " for i in range(n_steps):\n",
    "# get randomly selected ✬real✬ samples\n",
    "  X_real, y_real = generate_real_samples(dataset, half_batch)\n",
    "# update discriminator model weights\n",
    "  d_loss1, d_acc1 = d_model.train_on_batch(X_real, y_real)\n",
    "# generate ✬fake✬ examples\n",
    "  X_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n",
    "# update discriminator model weights\n",
    "  d_loss2, d_acc2 = d_model.train_on_batch(X_fake, y_fake)\n",
    "# prepare points in latent space as input for the generator\n",
    "  X_gan = generate_latent_points(latent_dim, n_batch)\n",
    "# create inverted labels for the fake samples\n",
    "  y_gan = ones((n_batch, 1))\n",
    "# update the generator via the discriminator✬s error\n",
    "  g_loss = gan_model.train_on_batch(X_gan, y_gan)\n",
    "# summarize loss on this batch\n",
    "  print('>%d, d1=%.3f, d2=%.3f g=%.3f, a1=%d, a2=%d' %\n",
    "          (i+1, d_loss1, d_loss2, g_loss, int(100*d_acc1), int(100*d_acc2)))\n",
    "# record history\n",
    "  d1_hist.append(d_loss1)\n",
    "  d2_hist.append(d_loss2)\n",
    "  g_hist.append(g_loss)\n",
    "  a1_hist.append(d_acc1)\n",
    "  a2_hist.append(d_acc2)\n",
    "# evaluate the model performance every ✬epoch✬\n",
    "  if (i+1) % bat_per_epo == 0:\n",
    "     summarize_performance(i, g_model, latent_dim)\n",
    " plot_history(d1_hist, d2_hist, g_hist, a1_hist, a2_hist)\n",
    "# make folder for results\n",
    "makedirs('results_baseline', exist_ok=True)\n",
    "# size of the latent space\n",
    "latent_dim = 50\n",
    "# create the discriminator\n",
    "discriminator = define_discriminator()\n",
    "# create the generator\n",
    "generator = define_generator(latent_dim)\n",
    "# create the gan\n",
    "gan_model = define_gan(generator, discriminator)\n",
    "# load image data\n",
    "dataset = load_real_samples()\n",
    "print(dataset.shape)\n",
    "# train model\n",
    "train(generator, discriminator, gan_model, dataset, latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfa0b40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
